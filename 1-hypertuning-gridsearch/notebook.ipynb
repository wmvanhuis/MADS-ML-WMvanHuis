{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercises \n",
    "# 1. Tune the network\n",
    "Run the experiment below, explore the different parameters (see suggestions below) and study the result with tensorboard. \n",
    "Make a single page (1 a4) report of your findings. Use your visualisation skills to communicate your most important findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from mltrainer import imagemodels, Trainer, TrainerSettings, ReportTypes, metrics\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from tomlserializer import TOMLSerializer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `tomlserializer` to easily keep track of our experiments, and to easily save the different things we did during our experiments.\n",
    "It can export things like settings and models to a simple `toml` file, which can be easily shared, checked and modified.\n",
    "\n",
    "First, we need the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 21:01:28.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m121\u001b[0m - \u001b[1mFolder already exists at /Users/wouter/.cache/mads_datasets/fashionmnist\u001b[0m\n",
      "\u001b[32m2025-09-17 21:01:28.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmads_datasets.base\u001b[0m:\u001b[36mdownload_data\u001b[0m:\u001b[36m124\u001b[0m - \u001b[1mFile already exists at /Users/wouter/.cache/mads_datasets/fashionmnist/fashionmnist.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "fashionfactory = DatasetFactoryProvider.create_factory(DatasetType.FASHION)\n",
    "preprocessor = BasePreprocessor()\n",
    "streamers = fashionfactory.create_datastreamer(batchsize=128, preprocessor=preprocessor)\n",
    "train = streamers[\"train\"]\n",
    "valid = streamers[\"valid\"]\n",
    "trainstreamer = train.stream()\n",
    "validstreamer = valid.stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a way to determine how well our model is performing. We will use accuracy as a metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set up a single experiment.\n",
    "\n",
    "- We will show the model batches of 64 images, \n",
    "- and for every epoch we will show the model 100 batches (trainsteps=100).\n",
    "- then, we will test how well the model is doing on unseen data (teststeps=100).\n",
    "- we will report our results during training to tensorboard, and report all configuration to a toml file.\n",
    "- we will log the results into a directory called \"modellogs\", but you could change this to whatever you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=100,\n",
    "    valid_steps=100,\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a very basic model: a model with three linear layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, units1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units1, units2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(units2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork(\n",
    "    num_classes=10, units1=512, units2=512, units3=512)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I developped the `tomlserializer` package, it is a useful tool to save configs, models and settings as a tomlfile; that way it is easy to track what you changed during your experiments.\n",
    "\n",
    "This package will 1. check if there is a `__dict__` attribute available, and if so, it will use that to extract the parameters that do not start with an underscore, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " 'num_classes': 10,\n",
       " 'units1': 512,\n",
       " 'units2': 512,\n",
       " 'units3': 512}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v for k, v in model.__dict__.items() if not k.startswith(\"_\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that if you want to add more parameters to the `.toml` file, eg `units3`, you can add them to the class like this:\n",
    "\n",
    "```python\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes: int, units1: int, units2: int, units3: int) -> None:\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.units1 = units1\n",
    "        self.units2 = units2\n",
    "        self.units3 = units3  # <-- add this line\n",
    "```\n",
    "\n",
    "And then it will be added to the `.toml` file. Check the result for yourself by using the `.save()` method of the `TomlSerializer` class like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tomlserializer = TOMLSerializer()\n",
    "tomlserializer.save(settings, \"settings.toml\")\n",
    "tomlserializer.save(model, \"model.toml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `settings.toml` and `model.toml` files to see what is in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `Trainer` class from my `mltrainer` module to train your model. It has the TOMLserializer integrated, so it will automatically save the settings and model to a toml file if you have added `TOML` as a reporttype in the settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 21:01:42.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210142\u001b[0m\n",
      "\u001b[32m2025-09-17 21:01:42.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 286.46it/s]\n",
      "\u001b[32m2025-09-17 21:01:43.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.7701 test 0.5959 metric ['0.7944']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 277.64it/s]\n",
      "\u001b[32m2025-09-17 21:01:43.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4908 test 0.5020 metric ['0.8116']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 292.59it/s]\n",
      "\u001b[32m2025-09-17 21:01:44.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.4640 test 0.4454 metric ['0.8409']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 292.46it/s]\n",
      "\u001b[32m2025-09-17 21:01:44.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.4234 test 0.4186 metric ['0.8520']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 100/100 [00:00<00:00, 287.10it/s]\n",
      "\u001b[32m2025-09-17 21:01:45.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.4014 test 0.4088 metric ['0.8509']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:02<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    settings=settings,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optim.Adam,\n",
    "    traindataloader=trainstreamer,\n",
    "    validdataloader=validstreamer,\n",
    "    scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    ")\n",
    "trainer.loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, check in the modellogs directory the results of your experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now loop this with a naive approach, called a grid-search (why do you think i call it naive?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Units: 512, 512, 512\n",
      "Units: 512, 512, 256\n",
      "Units: 512, 512, 128\n",
      "Units: 512, 256, 512\n",
      "Units: 512, 256, 256\n",
      "Units: 512, 256, 128\n",
      "Units: 512, 128, 512\n",
      "Units: 512, 128, 256\n",
      "Units: 512, 128, 128\n",
      "Units: 256, 512, 512\n",
      "Units: 256, 512, 256\n",
      "Units: 256, 512, 128\n",
      "Units: 256, 256, 512\n",
      "Units: 256, 256, 256\n",
      "Units: 256, 256, 128\n",
      "Units: 256, 128, 512\n",
      "Units: 256, 128, 256\n",
      "Units: 256, 128, 128\n",
      "Units: 128, 512, 512\n",
      "Units: 128, 512, 256\n",
      "Units: 128, 512, 128\n",
      "Units: 128, 256, 512\n",
      "Units: 128, 256, 256\n",
      "Units: 128, 256, 128\n",
      "Units: 128, 128, 512\n",
      "Units: 128, 128, 256\n",
      "Units: 128, 128, 128\n"
     ]
    }
   ],
   "source": [
    "units = [512, 256, 128]\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        for unit3 in units:\n",
    "            print(f\"Units: {unit1}, {unit2}, {unit3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, this might not be the best way to search for a model; some configurations will be better than others (can you predict up front what will be the best configuration?).\n",
    "\n",
    "So, feel free to improve upon the gridsearch by adding your own logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-09-17 21:01:53.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210153\u001b[0m\n",
      "\u001b[32m2025-09-17 21:01:53.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 288.42it/s]\n",
      "\u001b[32m2025-09-17 21:01:54.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5131 test 0.4296 metric ['0.8430']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 289.85it/s]\n",
      "\u001b[32m2025-09-17 21:01:56.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3644 test 0.3719 metric ['0.8667']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 291.13it/s]\n",
      "\u001b[32m2025-09-17 21:01:58.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3233 test 0.3690 metric ['0.8639']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 289.07it/s]\n",
      "\u001b[32m2025-09-17 21:02:00.177\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.2983 test 0.3548 metric ['0.8706']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 291.62it/s]\n",
      "\u001b[32m2025-09-17 21:02:01.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2821 test 0.3390 metric ['0.8819']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:08<00:00,  1.73s/it]\n",
      "\u001b[32m2025-09-17 21:02:01.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210201\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:01.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 290.43it/s]\n",
      "\u001b[32m2025-09-17 21:02:03.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5168 test 0.4086 metric ['0.8495']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 286.69it/s]\n",
      "\u001b[32m2025-09-17 21:02:05.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3657 test 0.4291 metric ['0.8332']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:05.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.4086, current loss 0.4291.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 291.78it/s]\n",
      "\u001b[32m2025-09-17 21:02:07.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3238 test 0.3714 metric ['0.8671']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 297.49it/s]\n",
      "\u001b[32m2025-09-17 21:02:08.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.2996 test 0.3518 metric ['0.8706']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 296.41it/s]\n",
      "\u001b[32m2025-09-17 21:02:10.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2802 test 0.3462 metric ['0.8766']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:08<00:00,  1.71s/it]\n",
      "\u001b[32m2025-09-17 21:02:10.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210210\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:10.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 297.20it/s]\n",
      "\u001b[32m2025-09-17 21:02:12.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5127 test 0.3996 metric ['0.8570']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 292.58it/s]\n",
      "\u001b[32m2025-09-17 21:02:13.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3648 test 0.3974 metric ['0.8589']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 293.92it/s]\n",
      "\u001b[32m2025-09-17 21:02:15.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3213 test 0.3396 metric ['0.8755']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 295.80it/s]\n",
      "\u001b[32m2025-09-17 21:02:17.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.2999 test 0.3951 metric ['0.8602']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:17.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3396, current loss 0.3951.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 294.88it/s]\n",
      "\u001b[32m2025-09-17 21:02:18.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2853 test 0.3347 metric ['0.8802']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:08<00:00,  1.70s/it]\n",
      "\u001b[32m2025-09-17 21:02:18.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210218\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:18.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 321.95it/s]\n",
      "\u001b[32m2025-09-17 21:02:20.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5300 test 0.4175 metric ['0.8504']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 326.60it/s]\n",
      "\u001b[32m2025-09-17 21:02:22.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3649 test 0.3827 metric ['0.8572']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 325.07it/s]\n",
      "\u001b[32m2025-09-17 21:02:23.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3295 test 0.3653 metric ['0.8648']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 322.82it/s]\n",
      "\u001b[32m2025-09-17 21:02:25.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3024 test 0.3661 metric ['0.8726']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:25.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3653, current loss 0.3661.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 324.10it/s]\n",
      "\u001b[32m2025-09-17 21:02:26.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2884 test 0.3308 metric ['0.8851']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.55s/it]\n",
      "\u001b[32m2025-09-17 21:02:26.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210226\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:26.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 320.29it/s]\n",
      "\u001b[32m2025-09-17 21:02:28.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5295 test 0.4234 metric ['0.8424']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 320.12it/s]\n",
      "\u001b[32m2025-09-17 21:02:29.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3671 test 0.3978 metric ['0.8528']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 314.10it/s]\n",
      "\u001b[32m2025-09-17 21:02:31.445\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3263 test 0.3672 metric ['0.8670']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 313.74it/s]\n",
      "\u001b[32m2025-09-17 21:02:33.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3057 test 0.3693 metric ['0.8702']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:33.041\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3672, current loss 0.3693.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 324.78it/s]\n",
      "\u001b[32m2025-09-17 21:02:34.588\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2850 test 0.3546 metric ['0.8719']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.58s/it]\n",
      "\u001b[32m2025-09-17 21:02:34.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210234\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:34.590\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 324.22it/s]\n",
      "\u001b[32m2025-09-17 21:02:36.139\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5271 test 0.4306 metric ['0.8460']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 320.21it/s]\n",
      "\u001b[32m2025-09-17 21:02:37.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3656 test 0.3961 metric ['0.8596']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 323.09it/s]\n",
      "\u001b[32m2025-09-17 21:02:39.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3265 test 0.3679 metric ['0.8646']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 329.67it/s]\n",
      "\u001b[32m2025-09-17 21:02:40.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3058 test 0.3509 metric ['0.8730']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 330.13it/s]\n",
      "\u001b[32m2025-09-17 21:02:42.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2826 test 0.3503 metric ['0.8707']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.54s/it]\n",
      "\u001b[32m2025-09-17 21:02:42.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210242\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:42.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 339.36it/s]\n",
      "\u001b[32m2025-09-17 21:02:43.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5409 test 0.4165 metric ['0.8529']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 336.84it/s]\n",
      "\u001b[32m2025-09-17 21:02:45.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3746 test 0.3792 metric ['0.8637']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 343.37it/s]\n",
      "\u001b[32m2025-09-17 21:02:46.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3366 test 0.3523 metric ['0.8729']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 341.03it/s]\n",
      "\u001b[32m2025-09-17 21:02:48.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3096 test 0.3679 metric ['0.8671']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:48.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3523, current loss 0.3679.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 350.87it/s]\n",
      "\u001b[32m2025-09-17 21:02:49.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2873 test 0.3417 metric ['0.8773']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.47s/it]\n",
      "\u001b[32m2025-09-17 21:02:49.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210249\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:49.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 354.67it/s]\n",
      "\u001b[32m2025-09-17 21:02:51.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5403 test 0.4296 metric ['0.8425']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 351.02it/s]\n",
      "\u001b[32m2025-09-17 21:02:52.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3736 test 0.4097 metric ['0.8571']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 340.43it/s]\n",
      "\u001b[32m2025-09-17 21:02:53.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3364 test 0.3599 metric ['0.8698']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 340.92it/s]\n",
      "\u001b[32m2025-09-17 21:02:55.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3084 test 0.3604 metric ['0.8679']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:55.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3599, current loss 0.3604.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 346.17it/s]\n",
      "\u001b[32m2025-09-17 21:02:56.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2901 test 0.3445 metric ['0.8741']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.45s/it]\n",
      "\u001b[32m2025-09-17 21:02:56.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210256\u001b[0m\n",
      "\u001b[32m2025-09-17 21:02:56.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 346.98it/s]\n",
      "\u001b[32m2025-09-17 21:02:58.375\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5465 test 0.4361 metric ['0.8419']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 339.86it/s]\n",
      "\u001b[32m2025-09-17 21:02:59.854\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3778 test 0.3890 metric ['0.8579']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 353.47it/s]\n",
      "\u001b[32m2025-09-17 21:03:01.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3352 test 0.3766 metric ['0.8611']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 351.16it/s]\n",
      "\u001b[32m2025-09-17 21:03:02.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3127 test 0.3999 metric ['0.8613']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:02.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3766, current loss 0.3999.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 340.69it/s]\n",
      "\u001b[32m2025-09-17 21:03:04.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2928 test 0.3676 metric ['0.8677']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:07<00:00,  1.45s/it]\n",
      "\u001b[32m2025-09-17 21:03:04.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210304\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:04.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 371.76it/s]\n",
      "\u001b[32m2025-09-17 21:03:05.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5366 test 0.4273 metric ['0.8399']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 376.33it/s]\n",
      "\u001b[32m2025-09-17 21:03:06.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3721 test 0.3943 metric ['0.8566']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 372.02it/s]\n",
      "\u001b[32m2025-09-17 21:03:08.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3322 test 0.3542 metric ['0.8728']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 381.28it/s]\n",
      "\u001b[32m2025-09-17 21:03:09.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3056 test 0.3579 metric ['0.8703']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:09.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3542, current loss 0.3579.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 375.32it/s]\n",
      "\u001b[32m2025-09-17 21:03:10.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2922 test 0.3324 metric ['0.8813']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.35s/it]\n",
      "\u001b[32m2025-09-17 21:03:10.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210310\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:10.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 369.40it/s]\n",
      "\u001b[32m2025-09-17 21:03:12.296\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5311 test 0.4294 metric ['0.8438']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 367.36it/s]\n",
      "\u001b[32m2025-09-17 21:03:13.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3671 test 0.3882 metric ['0.8614']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 362.75it/s]\n",
      "\u001b[32m2025-09-17 21:03:15.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3283 test 0.3667 metric ['0.8670']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 368.52it/s]\n",
      "\u001b[32m2025-09-17 21:03:16.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3067 test 0.3635 metric ['0.8655']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 380.18it/s]\n",
      "\u001b[32m2025-09-17 21:03:17.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2875 test 0.3422 metric ['0.8743']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.37s/it]\n",
      "\u001b[32m2025-09-17 21:03:17.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210317\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:17.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 374.87it/s]\n",
      "\u001b[32m2025-09-17 21:03:19.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5397 test 0.4510 metric ['0.8305']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 369.80it/s]\n",
      "\u001b[32m2025-09-17 21:03:20.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3711 test 0.3873 metric ['0.8622']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 368.34it/s]\n",
      "\u001b[32m2025-09-17 21:03:21.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3293 test 0.3956 metric ['0.8639']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:21.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3873, current loss 0.3956.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 370.78it/s]\n",
      "\u001b[32m2025-09-17 21:03:23.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3063 test 0.3395 metric ['0.8806']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 371.07it/s]\n",
      "\u001b[32m2025-09-17 21:03:24.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2887 test 0.3685 metric ['0.8665']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:24.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3395, current loss 0.3685.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.36s/it]\n",
      "\u001b[32m2025-09-17 21:03:24.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210324\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:24.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 409.19it/s]\n",
      "\u001b[32m2025-09-17 21:03:25.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5517 test 0.4292 metric ['0.8458']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 409.09it/s]\n",
      "\u001b[32m2025-09-17 21:03:27.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3780 test 0.3871 metric ['0.8589']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 406.88it/s]\n",
      "\u001b[32m2025-09-17 21:03:28.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3379 test 0.3688 metric ['0.8697']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 401.64it/s]\n",
      "\u001b[32m2025-09-17 21:03:29.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3094 test 0.3746 metric ['0.8624']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:29.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3688, current loss 0.3746.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 404.36it/s]\n",
      "\u001b[32m2025-09-17 21:03:30.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2953 test 0.3488 metric ['0.8759']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.24s/it]\n",
      "\u001b[32m2025-09-17 21:03:30.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210330\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:30.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 417.66it/s]\n",
      "\u001b[32m2025-09-17 21:03:31.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5444 test 0.4541 metric ['0.8364']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 414.98it/s]\n",
      "\u001b[32m2025-09-17 21:03:33.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3777 test 0.3994 metric ['0.8552']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 410.80it/s]\n",
      "\u001b[32m2025-09-17 21:03:34.440\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3381 test 0.3753 metric ['0.8651']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 405.15it/s]\n",
      "\u001b[32m2025-09-17 21:03:35.685\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3084 test 0.3460 metric ['0.8739']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 408.07it/s]\n",
      "\u001b[32m2025-09-17 21:03:36.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2941 test 0.3467 metric ['0.8789']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:36.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3460, current loss 0.3467.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.23s/it]\n",
      "\u001b[32m2025-09-17 21:03:36.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210336\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:36.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 415.64it/s]\n",
      "\u001b[32m2025-09-17 21:03:38.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5504 test 0.4279 metric ['0.8400']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 414.00it/s]\n",
      "\u001b[32m2025-09-17 21:03:39.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3833 test 0.4005 metric ['0.8576']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 415.16it/s]\n",
      "\u001b[32m2025-09-17 21:03:40.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3417 test 0.3595 metric ['0.8713']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 409.17it/s]\n",
      "\u001b[32m2025-09-17 21:03:41.796\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3151 test 0.3911 metric ['0.8581']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:41.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3595, current loss 0.3911.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 407.30it/s]\n",
      "\u001b[32m2025-09-17 21:03:43.035\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2953 test 0.3405 metric ['0.8792']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.22s/it]\n",
      "\u001b[32m2025-09-17 21:03:43.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210343\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:43.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 480.28it/s]\n",
      "\u001b[32m2025-09-17 21:03:44.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5590 test 0.4445 metric ['0.8397']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 473.27it/s]\n",
      "\u001b[32m2025-09-17 21:03:45.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3873 test 0.4013 metric ['0.8575']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 482.74it/s]\n",
      "\u001b[32m2025-09-17 21:03:46.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3415 test 0.3823 metric ['0.8563']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 484.70it/s]\n",
      "\u001b[32m2025-09-17 21:03:47.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3146 test 0.3559 metric ['0.8667']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 458.63it/s]\n",
      "\u001b[32m2025-09-17 21:03:48.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2946 test 0.3546 metric ['0.8701']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:05<00:00,  1.07s/it]\n",
      "\u001b[32m2025-09-17 21:03:48.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210348\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:48.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 456.57it/s]\n",
      "\u001b[32m2025-09-17 21:03:49.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5608 test 0.4296 metric ['0.8448']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 459.04it/s]\n",
      "\u001b[32m2025-09-17 21:03:50.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3920 test 0.4009 metric ['0.8569']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 459.82it/s]\n",
      "\u001b[32m2025-09-17 21:03:51.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3445 test 0.3673 metric ['0.8690']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 476.71it/s]\n",
      "\u001b[32m2025-09-17 21:03:52.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3182 test 0.3599 metric ['0.8698']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 477.74it/s]\n",
      "\u001b[32m2025-09-17 21:03:53.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2986 test 0.3583 metric ['0.8765']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:05<00:00,  1.10s/it]\n",
      "\u001b[32m2025-09-17 21:03:53.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210353\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:53.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 491.12it/s]\n",
      "\u001b[32m2025-09-17 21:03:54.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5671 test 0.4391 metric ['0.8453']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 475.66it/s]\n",
      "\u001b[32m2025-09-17 21:03:56.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3917 test 0.4156 metric ['0.8497']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 483.38it/s]\n",
      "\u001b[32m2025-09-17 21:03:57.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3472 test 0.3781 metric ['0.8603']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 481.97it/s]\n",
      "\u001b[32m2025-09-17 21:03:58.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3176 test 0.3574 metric ['0.8677']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 485.19it/s]\n",
      "\u001b[32m2025-09-17 21:03:59.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3037 test 0.3412 metric ['0.8739']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:05<00:00,  1.06s/it]\n",
      "\u001b[32m2025-09-17 21:03:59.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210359\u001b[0m\n",
      "\u001b[32m2025-09-17 21:03:59.175\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 413.54it/s]\n",
      "\u001b[32m2025-09-17 21:04:00.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5551 test 0.4644 metric ['0.8284']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 414.92it/s]\n",
      "\u001b[32m2025-09-17 21:04:01.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3808 test 0.3811 metric ['0.8653']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 418.34it/s]\n",
      "\u001b[32m2025-09-17 21:04:02.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3427 test 0.3477 metric ['0.8697']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 385.51it/s]\n",
      "\u001b[32m2025-09-17 21:04:04.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3135 test 0.3660 metric ['0.8699']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:04.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3477, current loss 0.3660.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 385.51it/s]\n",
      "\u001b[32m2025-09-17 21:04:05.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2978 test 0.3653 metric ['0.8681']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:05.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3477, current loss 0.3653.Counter 2/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.26s/it]\n",
      "\u001b[32m2025-09-17 21:04:05.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210405\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:05.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 399.93it/s]\n",
      "\u001b[32m2025-09-17 21:04:06.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5567 test 0.4422 metric ['0.8423']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 418.12it/s]\n",
      "\u001b[32m2025-09-17 21:04:07.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3841 test 0.3831 metric ['0.8608']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 413.84it/s]\n",
      "\u001b[32m2025-09-17 21:04:09.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3381 test 0.3664 metric ['0.8682']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 414.43it/s]\n",
      "\u001b[32m2025-09-17 21:04:10.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3166 test 0.3606 metric ['0.8723']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 420.94it/s]\n",
      "\u001b[32m2025-09-17 21:04:11.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.2988 test 0.3378 metric ['0.8795']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.23s/it]\n",
      "\u001b[32m2025-09-17 21:04:11.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210411\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:11.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 413.36it/s]\n",
      "\u001b[32m2025-09-17 21:04:12.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5620 test 0.4599 metric ['0.8307']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 413.27it/s]\n",
      "\u001b[32m2025-09-17 21:04:14.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3839 test 0.3954 metric ['0.8553']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 421.79it/s]\n",
      "\u001b[32m2025-09-17 21:04:15.270\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3436 test 0.3682 metric ['0.8688']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 413.96it/s]\n",
      "\u001b[32m2025-09-17 21:04:16.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3162 test 0.3827 metric ['0.8593']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:16.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3682, current loss 0.3827.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:01<00:00, 419.43it/s]\n",
      "\u001b[32m2025-09-17 21:04:17.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3010 test 0.3289 metric ['0.8785']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:06<00:00,  1.22s/it]\n",
      "\u001b[32m2025-09-17 21:04:17.703\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210417\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:17.704\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 505.98it/s]\n",
      "\u001b[32m2025-09-17 21:04:18.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5840 test 0.4425 metric ['0.8392']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 511.91it/s]\n",
      "\u001b[32m2025-09-17 21:04:19.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3949 test 0.3991 metric ['0.8567']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 494.75it/s]\n",
      "\u001b[32m2025-09-17 21:04:20.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3480 test 0.3821 metric ['0.8648']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 511.32it/s]\n",
      "\u001b[32m2025-09-17 21:04:21.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3243 test 0.3765 metric ['0.8631']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 501.77it/s]\n",
      "\u001b[32m2025-09-17 21:04:22.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3038 test 0.3458 metric ['0.8746']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:05<00:00,  1.01s/it]\n",
      "\u001b[32m2025-09-17 21:04:22.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210422\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:22.761\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 503.76it/s]\n",
      "\u001b[32m2025-09-17 21:04:23.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5697 test 0.4599 metric ['0.8346']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 488.50it/s]\n",
      "\u001b[32m2025-09-17 21:04:24.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3960 test 0.3911 metric ['0.8603']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 502.25it/s]\n",
      "\u001b[32m2025-09-17 21:04:25.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3539 test 0.3642 metric ['0.8685']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 506.41it/s]\n",
      "\u001b[32m2025-09-17 21:04:26.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3267 test 0.3602 metric ['0.8708']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 501.03it/s]\n",
      "\u001b[32m2025-09-17 21:04:27.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3072 test 0.3608 metric ['0.8675']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:27.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3602, current loss 0.3608.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:05<00:00,  1.02s/it]\n",
      "\u001b[32m2025-09-17 21:04:27.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210427\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:27.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 493.23it/s]\n",
      "\u001b[32m2025-09-17 21:04:28.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5743 test 0.4371 metric ['0.8455']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 514.45it/s]\n",
      "\u001b[32m2025-09-17 21:04:29.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.3879 test 0.4079 metric ['0.8493']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 502.64it/s]\n",
      "\u001b[32m2025-09-17 21:04:30.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3465 test 0.4065 metric ['0.8501']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 502.35it/s]\n",
      "\u001b[32m2025-09-17 21:04:31.932\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3234 test 0.3686 metric ['0.8651']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 494.21it/s]\n",
      "\u001b[32m2025-09-17 21:04:32.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3043 test 0.3443 metric ['0.8750']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:05<00:00,  1.02s/it]\n",
      "\u001b[32m2025-09-17 21:04:32.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210432\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:32.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 537.82it/s]\n",
      "\u001b[32m2025-09-17 21:04:33.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.6070 test 0.4561 metric ['0.8343']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 542.61it/s]\n",
      "\u001b[32m2025-09-17 21:04:34.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4040 test 0.4116 metric ['0.8544']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 542.42it/s]\n",
      "\u001b[32m2025-09-17 21:04:35.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3653 test 0.3886 metric ['0.8602']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 537.32it/s]\n",
      "\u001b[32m2025-09-17 21:04:36.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3377 test 0.3701 metric ['0.8711']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 545.42it/s]\n",
      "\u001b[32m2025-09-17 21:04:37.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3179 test 0.3758 metric ['0.8599']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:37.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3701, current loss 0.3758.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:04<00:00,  1.05it/s]\n",
      "\u001b[32m2025-09-17 21:04:37.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210437\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:37.718\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 544.08it/s]\n",
      "\u001b[32m2025-09-17 21:04:38.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5987 test 0.4774 metric ['0.8326']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 540.97it/s]\n",
      "\u001b[32m2025-09-17 21:04:39.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4084 test 0.3998 metric ['0.8616']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 535.83it/s]\n",
      "\u001b[32m2025-09-17 21:04:40.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3590 test 0.4057 metric ['0.8540']\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:40.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m252\u001b[0m - \u001b[1mbest loss: 0.3998, current loss 0.4057.Counter 1/10.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 544.69it/s]\n",
      "\u001b[32m2025-09-17 21:04:41.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3347 test 0.3991 metric ['0.8577']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 542.82it/s]\n",
      "\u001b[32m2025-09-17 21:04:42.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3142 test 0.3632 metric ['0.8678']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:04<00:00,  1.05it/s]\n",
      "\u001b[32m2025-09-17 21:04:42.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m24\u001b[0m - \u001b[1mLogging to modellogs/20250917-210442\u001b[0m\n",
      "\u001b[32m2025-09-17 21:04:42.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound earlystop_kwargs in settings.Set to None if you dont want earlystopping.\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 544.76it/s]\n",
      "\u001b[32m2025-09-17 21:04:43.418\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 0 train 0.5936 test 0.4596 metric ['0.8381']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 539.21it/s]\n",
      "\u001b[32m2025-09-17 21:04:44.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 1 train 0.4043 test 0.3967 metric ['0.8611']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 533.64it/s]\n",
      "\u001b[32m2025-09-17 21:04:45.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 2 train 0.3617 test 0.3925 metric ['0.8621']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 545.22it/s]\n",
      "\u001b[32m2025-09-17 21:04:46.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 3 train 0.3371 test 0.3753 metric ['0.8611']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 468/468 [00:00<00:00, 546.62it/s]\n",
      "\u001b[32m2025-09-17 21:04:47.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mreport\u001b[0m:\u001b[36m209\u001b[0m - \u001b[1mEpoch 4 train 0.3203 test 0.3571 metric ['0.8712']\u001b[0m\n",
      "100%|\u001b[38;2;30;71;6m██████████\u001b[0m| 5/5 [00:04<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "units = [512, 256, 128]\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "settings = TrainerSettings(\n",
    "    epochs=5,\n",
    "    metrics=[accuracy],\n",
    "    logdir=\"modellogs\",\n",
    "    train_steps=len(train),\n",
    "    valid_steps=len(valid),\n",
    "    reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.TOML],\n",
    ")\n",
    "\n",
    "for unit1 in units:\n",
    "    for unit2 in units:\n",
    "        for unit3 in units:\n",
    "\n",
    "            model = NeuralNetwork(num_classes=10, units1=unit1, units2=unit2, units3=unit3)\n",
    "\n",
    "            trainer = Trainer(\n",
    "                model=model,\n",
    "                settings=settings,\n",
    "                loss_fn=loss_fn,\n",
    "                optimizer=optim.Adam,\n",
    "                traindataloader=trainstreamer,\n",
    "                validdataloader=validstreamer,\n",
    "                scheduler=optim.lr_scheduler.ReduceLROnPlateau\n",
    "            )\n",
    "            trainer.loop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we have set the ReportType to TOML, you will find in every log dir a model.toml and settings.toml file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the experiment, and study the result with tensorboard. \n",
    "\n",
    "Locally, it is easy to do that with VS code itself. On the server, you have to take these steps:\n",
    "\n",
    "- in the terminal, `cd` to the location of the repository\n",
    "- activate the python environment for the shell. Note how the correct environment is being activated.\n",
    "- run `tensorboard --logdir=modellogs` in the terminal\n",
    "- tensorboard will launch at `localhost:6006` and vscode will notify you that the port is forwarded\n",
    "- you can either press the `launch` button in VScode or open your local browser at `localhost:6006`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio-example",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
